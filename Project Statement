<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Project 3 Page</title>
    <link rel="stylesheet" href="stylepage.css">
</head>
<body>
    <!-- My Learning Model and It's Manifestation -->
    <h1>With the AI learning module I have found that that in order to prove the consequences of the learning model, one has to input the proper sample. From reading  Buolawmini's book “Unmasking AI” I believe that there is a paradox between those who are compiling the data inputted into AI based on what they argue is “true or false” which is evidenced on the logic they input. You can choose the parameters on which algorithms you want to make the reasoning you wish. Now, with all this evidence the algorithms will produce degraded results as the parameters are implemented per the AI learning method. Based on the logic the more you assume, the easier it is to prove. However is AI actually solving the problem which is trying to be predicted? 
Dr. Joy Boulommi laments that the use of AI for facial recognition and its inherently biased outcomes or lack thereof are detrimental to the intended use. Her research into the algorithms and the use of facial recognition and its bias towards those with dark complexions creates a litany of significant injustices laid upon people of color. She asserts that AI bias is creating real-world harm across an array of fields amongst those who are getting hired, those who are getting a mortgage, who gets into college and much more. Her poetic prose “Unmasking AI: My Misson to Protect What is Human in a World of Machines” has received accolades amongst her peers. However, the massive corporations who use AI for their technological based decision making without human intervention, there is an unsettling sentiment towards this logic. This lays a foundation that not only shows an implicit laziness amongst those who hire but it shows that in the most critical of decision-making capabilities, these corporations are not utilizing a human component to hire those who will greatly affect the workplace they are joining.
What is most concerning to Boulommi is the current modus operandi of today’s AI companies and their unethical use of information. She claims it is a form of  “data colonialism” with a full “disregard for consent” and I could not agree more in her assertation of how our personal recognition is being used. To begin the op-ed piece of this, the normalization of the use of our faces, fingerprints and retina recognition has left those who value security reeling. The ways in which we collectively hand out such personal data and vulnerabilities to those who continually wreak havoc upon the population is astounding. Beyond the fact that our DNA, facial structures, fingerprints, and retinal data have now been harvested for the sake of “security” purposes, we capitulate to a point where we would not have a leg to stand on if we were to finally dissent to the rational. And I have not begun to speculate on those who are behind the 23 and Me and similar “genetic coding and identification” businesses truly represent.
Where the algorithmic bias can be manifested and manipulated is vastly profound and that is where we, as citizens of the world need to be concerned. Dr. Boulommi sheds more than just “light” on the ways in which we are being manipulated. She identifies the ways in which this technology is being implicitly used for the manipulation and segregation of particular populations. While her claims were originally based on the hue of one’s skin, we can reasonably ascertain that it definitely could not be restricted to something as categorical as that. Once they begin to really focus and home in on the “Hitler Values” as I will call them, there is no bound to where they can end the manipulation of the  “have’s and have nots.” And there in-lies the problem.
With this assignment, I took a very topical approach to the learning model based off of the study material we were given which was anecdotal and easy to follow simply because this class is not intended to sculpt the minds of true computer scientists. With that, as much as I am profoundly inept with computer logic, science, and any other derivative of what computer logic may be, I allowed myself to be truly evaluated and challenged with the coursework. While much of the literature, ideologies and overarching themes presented in the course were ostensibly biased towards the “anyone who is not a white male” I can see the forest through the trees with some of the content. 
My learning model began with using my two black pit bull dogs to initiate the learning process model for this assignment. This was followed by two other variables that had nothing to do with dogs or color. When I initially recorded my learning model, I used my dogs in the first iteration of the recordings followed by two other inanimate objects only to find that while the tab which said “hold to record” was not an articulate directive of what was required. As it turns out, you needed to press the button multiple times to capture images that would facilitate a valid learning model. 
Once I realized that I had a small sample size of pictures due to the inadequacy of the direction, I pressed on with the same subjects…and this is where I realized that Boulommi was accurate in her studies as I achieved the exact result she described. My black pit bull, black face, black eyes with significant lighting and the label of a “dog” would NOT correlate a “dog” when I would test the picture set I took. At one point I had taken 340 pictures of my dog and I would still get results that would label another example of a dog as something else. So I switched my dog for my white hand and wouldn’t you know…I get immediate results. So now I’m left with a long conversation with my dogs that not only are they objectified by their breed but now the color of their fur. Yes, we have a long conversation to be had on the validity of AI recognition and those that fully trust in it. It is my belief that those who choose to utilize it are the same that offer zero rebuttal to the massive amounts of weapons and money sent to the nation of Israel. Meaning, those who willingly apply the concepts of inadequate technology will continue the perpetuation of disregard for anyone who does not look like they believe can work in their environment. And the disregard continues…
</h1>
    <p>While my project was very simplistic at is core, I found that not only can recognition be misrepresented, I can be done without truly insideous intentions. What I now understand is the data we value needs to not only be qunatitative but also requires checks and balances amongst peers. We have to do better with the tools we are presenting to the world. While I have found solution sets to address this issue, I truly believe that if AI was regulated much like our government and those who develop the technology are immediately directed to another objective entity to provide "checks and balances" to the algorithm would profoundly reduce implicit bias.</p>
<h2>Project Objectives</h2>
    <p>I initially recorded pictures of my dog, a globe and a banana to test the recognition. What I found to be most concerning as well as inline with Dr. Boulommi's book is that my very deep black pitbull could not be recognized. After mulitple attempts with various lighting and backgrounds. True to scientific methods, I tested it with a stuffed dog that was a lighter tone and it was perfection when tested. The algorithm detected a dog every time. I decided to exchange the dog for my hand to make this not only easier for me but to also elicit a response from the machine that would warrant a productive model. </p>

       <h3><a href="index.html">Home Page</a></h3>
</body>
</html>
